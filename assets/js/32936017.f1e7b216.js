"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[946],{621:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>d,contentTitle:()=>r,default:()=>p,frontMatter:()=>o,metadata:()=>s,toc:()=>l});const s=JSON.parse('{"id":"chapter3/chapter3-detail","title":"Humanoid Manipulation and Embodied Interaction","description":"Fundamentals of Humanoid Manipulation","source":"@site/docs/chapter3/detail.md","sourceDirName":"chapter3","slug":"/chapter3/chapter3-detail","permalink":"/docs/chapter3/chapter3-detail","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/chapter3/detail.md","tags":[],"version":"current","frontMatter":{"id":"chapter3-detail","title":"Humanoid Manipulation and Embodied Interaction"},"sidebar":"tutorialSidebar","previous":{"title":"Physical Intelligence and Motion Architecture","permalink":"/docs/chapter2/chapter2-intro"}}');var t=i(4848),a=i(8453);const o={id:"chapter3-detail",title:"Humanoid Manipulation and Embodied Interaction"},r="03: Humanoid Manipulation and Embodied Interaction",d={},l=[{value:"Kinematics for Robotic Arms and Hands",id:"kinematics-for-robotic-arms-and-hands",level:2},{value:"Dynamics and Force Control",id:"dynamics-and-force-control",level:2},{value:"Grasping Models and Object Interaction",id:"grasping-models-and-object-interaction",level:2},{value:"Types of Grasps",id:"types-of-grasps",level:2},{value:"Visual Perception for Manipulation",id:"visual-perception-for-manipulation",level:2},{value:"Embodied Interaction and Safety",id:"embodied-interaction-and-safety",level:2},{value:"Learning-Based Manipulation",id:"learning-based-manipulation",level:2}];function c(n){const e={em:"em",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,a.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.header,{children:(0,t.jsxs)(e.h1,{id:"03-humanoid-manipulation-and-embodied-interaction",children:["03: ",(0,t.jsx)(e.em,{children:"Humanoid Manipulation and Embodied Interaction"})]})}),"\n",(0,t.jsx)(e.p,{children:"Fundamentals of Humanoid Manipulation"}),"\n",(0,t.jsx)(e.p,{children:"Humanoid manipulation focuses on controlling arms, hands, and upper-body segments to interact with physical objects. This includes reaching, grasping, lifting, and coordinating dual-arm actions. The system must manage joint coordination, object dynamics, and collision-aware motion."}),"\n",(0,t.jsx)(e.p,{children:"Core Objectives"}),"\n",(0,t.jsx)(e.p,{children:"Precise end-effector placement"}),"\n",(0,t.jsx)(e.p,{children:"Stable and adaptive grasping"}),"\n",(0,t.jsx)(e.p,{children:"Smooth multi-joint coordination"}),"\n",(0,t.jsx)(e.p,{children:"Safe interaction with humans and objects"}),"\n",(0,t.jsx)(e.p,{children:"Manipulation depends on robust models of kinematics, dynamics, and contact forces."}),"\n",(0,t.jsx)(e.h2,{id:"kinematics-for-robotic-arms-and-hands",children:"Kinematics for Robotic Arms and Hands"}),"\n",(0,t.jsx)(e.p,{children:"Kinematics defines how joint movements produce end-effector positions and orientations. Humanoid robots employ forward kinematics to predict tool position and inverse kinematics to compute joint angles for desired poses."}),"\n",(0,t.jsx)(e.p,{children:"Key Concepts"}),"\n",(0,t.jsx)(e.p,{children:"Joint space vs. task space"}),"\n",(0,t.jsx)(e.p,{children:"Jacobian matrices"}),"\n",(0,t.jsx)(e.p,{children:"Redundancy resolution"}),"\n",(0,t.jsx)(e.p,{children:"Joint limit and singularity handling"}),"\n",(0,t.jsx)(e.p,{children:"These mathematical models ensure accurate manipulation even in cluttered environments."}),"\n",(0,t.jsx)(e.h2,{id:"dynamics-and-force-control",children:"Dynamics and Force Control"}),"\n",(0,t.jsx)(e.p,{children:"Robotic hands and arms must exert controlled forces during interaction. Dynamics modeling allows the system to compensate for inertia, external loads, and joint torques."}),"\n",(0,t.jsx)(e.p,{children:"Control Approaches"}),"\n",(0,t.jsx)(e.p,{children:"Impedance control"}),"\n",(0,t.jsx)(e.p,{children:"Admittance control"}),"\n",(0,t.jsx)(e.p,{children:"Hybrid force\u2013position strategies"}),"\n",(0,t.jsx)(e.p,{children:"Model-based torque regulation"}),"\n",(0,t.jsx)(e.p,{children:"These methods enable tasks such as pushing, pulling, fastening, or precision assembly."}),"\n",(0,t.jsx)(e.h2,{id:"grasping-models-and-object-interaction",children:"Grasping Models and Object Interaction"}),"\n",(0,t.jsx)(e.p,{children:"Grasp generation involves analyzing object geometry, friction, and grasp stability. The robot selects finger placements and wrist orientations to ensure a secure hold."}),"\n",(0,t.jsx)(e.h2,{id:"types-of-grasps",children:"Types of Grasps"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"\u2705 Power grasps"}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"\u2705 Precision grasps"}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"\u2705 Multi-fingered enveloping grasps"}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"\u2705 Pinch grasps"}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"\u2705 Grasp Planning Considerations"}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"\u2705 Contact point selection"}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"\u2705 Slip prediction"}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"\u2705 Force distribution"}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"\u2705 Object deformation handling"}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(e.p,{children:"Robust grasping is essential for handling diverse tools and artifacts."}),"\n",(0,t.jsx)(e.h2,{id:"visual-perception-for-manipulation",children:"Visual Perception for Manipulation"}),"\n",(0,t.jsx)(e.p,{children:"Humanoid robots rely on vision to locate objects, predict shapes, and determine interaction strategies."}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"Common Visual Tasks"}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"Object detection"}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"Pose estimation"}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"Depth analysis"}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"Semantic segmentation"}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(e.p,{children:"The visual system guides arm trajectories and supports real-time corrections."}),"\n",(0,t.jsx)(e.h2,{id:"embodied-interaction-and-safety",children:"Embodied Interaction and Safety"}),"\n",(0,t.jsx)(e.p,{children:"Humanoid robots engage in shared environments with humans. Safety mechanisms ensure compliant behavior, avoid accidental collisions, and maintain predictable responses."}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"Safety Elements"}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"Collision detection"}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"Soft contact handling"}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"Adaptive stiffness adjustments"}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"Predictive motion patterns"}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(e.p,{children:"These mechanisms combine sensor input with control models to create safe and natural interactions."}),"\n",(0,t.jsx)(e.h2,{id:"learning-based-manipulation",children:"Learning-Based Manipulation"}),"\n",(0,t.jsx)(e.p,{children:"Learning systems expand manipulation capabilities beyond hand-coded controllers. Data-driven approaches allow robots to acquire skills from demonstrations and experiences."}),"\n",(0,t.jsx)(e.p,{children:(0,t.jsx)(e.strong,{children:"Learning Techniques"})}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"Imitation learning"}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"Reinforcement learning"}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"Skill parameterization"}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"Vision\u2013action learning models"}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(e.p,{children:"These models enhance dexterity, improve precision, and support complex task automation."})]})}function p(n={}){const{wrapper:e}={...(0,a.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(c,{...n})}):c(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>o,x:()=>r});var s=i(6540);const t={},a=s.createContext(t);function o(n){const e=s.useContext(a);return s.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function r(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(t):n.components||t:o(n.components),s.createElement(a.Provider,{value:e},n.children)}}}]);